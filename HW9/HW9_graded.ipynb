{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DesiPilla/DSPS_dPilla/blob/master/HW9/higgsbosonSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vwvk8bzJUv-w"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "-xpw06PzTsU6",
    "outputId": "697e9627-78a3-484b-e24e-93059e7e2102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1JoRqCoDVqK"
   },
   "source": [
    "## Download Data from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nS4S7msAPK_R"
   },
   "source": [
    "- Download the Higgs boson data from Kaggle (programmatically within the notebook)\n",
    "see how I did it in the Titanic Trees notebook https://github.com/fedhere/DSPS/blob/master/lab9/titanictree.ipynb\n",
    "\n",
    "find the correct API link here https://www.kaggle.com/c/higgs-boson/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "7MP1xlkGDVRD",
    "outputId": "dd200335-b41f-4081-e1aa-5ebb509b3650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.9.11)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YiDVRqzFDdNO",
    "outputId": "766fd803-2173-4c7d-b03a-27b36821e086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/dsps\n"
     ]
    }
   ],
   "source": [
    "cd 'drive/My Drive/dsps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WyY2jIhUEYKA"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "rKT3A0JoJr-P",
    "outputId": "38bd8a74-e92f-4834-cb26-6841963600f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/     \u001b[01;34mkaggleHiggsBoson\u001b[0m/           pluto_18v2_1.csv\n",
      "data.csv  nyc_pluto_18v2_1_csv.zip    PLUTODD18v2.1.pdf\n",
      "\u001b[01;34mkaggle\u001b[0m/   nyc_pluto_18v2_1_csv.zip.1  PlutoReadme18v2.1.pdf\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SyjFZTOIJZq3",
    "outputId": "91e2ef5c-111c-49f7-83f9-f81524b7e05f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/dsps/kaggle\n"
     ]
    }
   ],
   "source": [
    "cd kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsc_AS2kHlp_"
   },
   "outputs": [],
   "source": [
    "cp kaggle.json ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oJ-WvVSBFLS3",
    "outputId": "76c1dc9f-0788-4380-849d-7e4d9eebf681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle.json\n"
     ]
    }
   ],
   "source": [
    "ls ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MOCbU-UvJ52X",
    "outputId": "ec489a95-86c2-4ce6-9797-8ef39d58e38e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.kaggle\n"
     ]
    }
   ],
   "source": [
    "cd ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ovLEgJSHI6AR"
   },
   "outputs": [],
   "source": [
    "!chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xC2Z2KVWKFmI"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "envs = json.load(open(\"kaggle.json\", \"r\"))\n",
    "os.environ[\"catherineharty\"] = envs['username']\n",
    "os.environ[\"824253b26696e60f3f970caa98c670cf\"] = envs['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I01rJB5BKTeY",
    "outputId": "38654523-dd73-4133-f6c8-e3ef36c7b6e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/dsps\n"
     ]
    }
   ],
   "source": [
    "cd '../../content/drive/My Drive/dsps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9VlK0pL1K1Gw",
    "outputId": "3a666510-8b58-4097-8041-01be89dbc97c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘kaggleHiggsBoson’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir kaggleHiggsBoson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zEU-FLt8K7UE",
    "outputId": "eb30c90b-2726-4afe-9a58-9e9d03517097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/dsps/kaggleHiggsBoson\n"
     ]
    }
   ],
   "source": [
    "cd kaggleHiggsBoson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "nO6iBjzCK9Rx",
    "outputId": "22b87485-5bea-49d6-e9ea-e505a3d3377b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "ref                                                      title                                               size  lastUpdated          downloadCount  \n",
      "-------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
      "tristan581/17k-apple-app-store-strategy-games            17K Mobile Strategy Games                            8MB  2019-08-26 08:22:16          10302  \n",
      "gustavomodelli/forest-fires-in-brazil                    Forest Fires in Brazil                              31KB  2019-08-24 16:09:16          11335  \n",
      "akhilv11/border-crossing-entry-data                      Border Crossing Entry Data                           4MB  2019-08-21 14:51:34           4892  \n",
      "rajeevw/ufcdata                                          UFC-Fight historical data from 1993 to 2019          3MB  2019-07-05 09:58:02           5841  \n",
      "shuyangli94/food-com-recipes-and-user-interactions       Food.com Recipes and Interactions                  267MB  2019-10-12 06:30:37           3303  \n",
      "chirin/africa-economic-banking-and-systemic-crisis-data  Africa Economic, Banking and Systemic Crisis Data   14KB  2019-07-21 02:00:17           3687  \n",
      "ruslankl/european-union-lgbt-survey-2012                 EU LGBT Survey                                     610KB  2019-07-19 11:15:25           1587  \n",
      "kapilverma/hindi-bible                                   Hindi Bible                                          5MB  2019-09-07 18:04:35            324  \n",
      "jojoker/singapore-airbnb                                 Singapore Airbnb                                   350KB  2019-09-25 22:05:44           1980  \n",
      "hmavrodiev/sofia-air-quality-dataset                     Sofia air quality dataset                            3GB  2019-09-14 05:48:09           1288  \n",
      "mabusalah/brent-oil-prices                               Brent Oil Prices                                    38KB  2019-10-14 12:31:05           1420  \n",
      "nitinsss/military-expenditure-of-countries-19602019      Military Spending of Countries (1960-2019)          55KB  2019-10-10 12:17:37           2577  \n",
      "irinachuchueva/russian-wholesale-electricity-market      Russian Wholesale Electricity Market                 1MB  2019-10-09 08:20:57            551  \n",
      "smid80/canadian-federal-election-results-timeseries      Canadian Federal Election Results (Timeseries)      18MB  2019-10-09 11:08:29            581  \n",
      "brkurzawa/us-breweries                                   US Breweries                                        76KB  2019-10-02 03:15:27           1646  \n",
      "srikantsahu/co2-and-ghg-emission-data                    CO2 and GHG emission data                           91KB  2019-09-26 20:10:59           1574  \n",
      "pascalbliem/european-social-survey-ess-8-ed21-201617     European Social Survey (ESS) 8 ed2.1 (2016/17)      10MB  2019-09-29 07:30:37            589  \n",
      "grikomsn/amazon-cell-phones-reviews                      Amazon Cell Phones Reviews                          10MB  2019-09-29 02:26:48           2221  \n",
      "valentynsichkar/traffic-signs-preprocessed               Traffic Signs Preprocessed                            0B  2019-08-31 18:22:11           1217  \n",
      "hmavrodiev/london-bike-sharing-dataset                   London bike sharing dataset                        165KB  2019-10-10 12:49:37           2746  \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPeW-pjDUhsp"
   },
   "source": [
    "In order to download the data, I had to accept the rules and verify my account on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "T_GgS2XtFEVc",
    "outputId": "29130d00-cca6-4743-edf6-4b2a2d004575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "random_submission.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "training.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "HiggsBosonCompetition_AMSMetric_rev1.py: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c higgs-boson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "f7-UQVjpLVcb",
    "outputId": "da4b55ff-4aa5-49f9-d574-12170adb7372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HiggsBosonCompetition_AMSMetric_rev1.py  test.zip      training.zip\n",
      "random_submission.zip                    training.csv\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9n01LzGYWMGW"
   },
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMuvMJgOnlYo"
   },
   "source": [
    "\n",
    "- Read in the training data. Split the provided training data into a training and a test set. \n",
    "The last 2 columns are what you want to predict: \"weight\" and \"label\".\n",
    "Remove them from the input data and create a separate variable label and a separate variable weight, which will be your target variables for, respectively, classification and regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "83TI5ZHIEIqU",
    "outputId": "28735454-535a-441e-e7c2-26a0064ff557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  training.zip\n",
      "replace training.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: training.csv            \n"
     ]
    }
   ],
   "source": [
    "!unzip training.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "aQThom3HUraF",
    "outputId": "466746b3-18e9-4df7-b48a-0dc635072c38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>DER_pt_ratio_lep_tau</th>\n",
       "      <th>DER_met_phi_centrality</th>\n",
       "      <th>DER_lep_eta_centrality</th>\n",
       "      <th>PRI_tau_pt</th>\n",
       "      <th>PRI_tau_eta</th>\n",
       "      <th>PRI_tau_phi</th>\n",
       "      <th>PRI_lep_pt</th>\n",
       "      <th>PRI_lep_eta</th>\n",
       "      <th>PRI_lep_phi</th>\n",
       "      <th>PRI_met</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.91</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>197.760</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1.396</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32.638</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.381</td>\n",
       "      <td>51.626</td>\n",
       "      <td>2.273</td>\n",
       "      <td>-2.414</td>\n",
       "      <td>16.824</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>258.733</td>\n",
       "      <td>2</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>125.157</td>\n",
       "      <td>0.879</td>\n",
       "      <td>1.414</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>42.014</td>\n",
       "      <td>2.039</td>\n",
       "      <td>-3.011</td>\n",
       "      <td>36.918</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.103</td>\n",
       "      <td>44.704</td>\n",
       "      <td>-1.916</td>\n",
       "      <td>164.546</td>\n",
       "      <td>1</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>197.814</td>\n",
       "      <td>3.776</td>\n",
       "      <td>1.414</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>32.154</td>\n",
       "      <td>-0.705</td>\n",
       "      <td>-2.093</td>\n",
       "      <td>121.409</td>\n",
       "      <td>-0.953</td>\n",
       "      <td>1.052</td>\n",
       "      <td>54.283</td>\n",
       "      <td>-2.186</td>\n",
       "      <td>260.414</td>\n",
       "      <td>1</td>\n",
       "      <td>44.251</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>75.968</td>\n",
       "      <td>2.354</td>\n",
       "      <td>-1.285</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>22.647</td>\n",
       "      <td>-1.655</td>\n",
       "      <td>0.010</td>\n",
       "      <td>53.321</td>\n",
       "      <td>-0.522</td>\n",
       "      <td>-3.100</td>\n",
       "      <td>31.082</td>\n",
       "      <td>0.060</td>\n",
       "      <td>86.062</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>57.983</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-1.385</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>28.209</td>\n",
       "      <td>-2.197</td>\n",
       "      <td>-2.231</td>\n",
       "      <td>29.774</td>\n",
       "      <td>0.798</td>\n",
       "      <td>1.569</td>\n",
       "      <td>2.723</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>53.131</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventId  DER_mass_MMC  ...  PRI_jet_subleading_phi  PRI_jet_all_pt\n",
       "0   100000       138.470  ...                  -2.475         113.497\n",
       "1   100001       160.937  ...                -999.000          46.226\n",
       "2   100002      -999.000  ...                -999.000          44.251\n",
       "3   100003       143.905  ...                -999.000          -0.000\n",
       "4   100004       175.864  ...                -999.000           0.000\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higgsData = pd.read_csv('training.csv')\n",
    "weights = higgsData['Weight'].values\n",
    "labels = higgsData['Label'].values\n",
    "higgsData.drop(columns = ['Weight', 'Label'], inplace = True)\n",
    "\n",
    "higgsData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "UjYc20zgVgaU",
    "outputId": "680c8189-b1d5-49b6-8850-90c9983de2c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>DER_pt_ratio_lep_tau</th>\n",
       "      <th>DER_met_phi_centrality</th>\n",
       "      <th>DER_lep_eta_centrality</th>\n",
       "      <th>PRI_tau_pt</th>\n",
       "      <th>PRI_tau_eta</th>\n",
       "      <th>PRI_tau_phi</th>\n",
       "      <th>PRI_lep_pt</th>\n",
       "      <th>PRI_lep_eta</th>\n",
       "      <th>PRI_lep_phi</th>\n",
       "      <th>PRI_met</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>224999.500000</td>\n",
       "      <td>-49.023079</td>\n",
       "      <td>49.239819</td>\n",
       "      <td>81.181982</td>\n",
       "      <td>57.895962</td>\n",
       "      <td>-708.420675</td>\n",
       "      <td>-601.237051</td>\n",
       "      <td>-709.356603</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>18.917332</td>\n",
       "      <td>158.432217</td>\n",
       "      <td>1.437609</td>\n",
       "      <td>-0.128305</td>\n",
       "      <td>-708.985189</td>\n",
       "      <td>38.707419</td>\n",
       "      <td>-0.010973</td>\n",
       "      <td>-0.008171</td>\n",
       "      <td>46.660207</td>\n",
       "      <td>-0.019507</td>\n",
       "      <td>0.043543</td>\n",
       "      <td>41.717235</td>\n",
       "      <td>-0.010119</td>\n",
       "      <td>209.797178</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>-348.329567</td>\n",
       "      <td>-399.254314</td>\n",
       "      <td>-399.259788</td>\n",
       "      <td>-692.381204</td>\n",
       "      <td>-709.121609</td>\n",
       "      <td>-709.118631</td>\n",
       "      <td>73.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72168.927986</td>\n",
       "      <td>406.345647</td>\n",
       "      <td>35.344886</td>\n",
       "      <td>40.828691</td>\n",
       "      <td>63.655682</td>\n",
       "      <td>454.480565</td>\n",
       "      <td>657.972302</td>\n",
       "      <td>453.019877</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>22.273494</td>\n",
       "      <td>115.706115</td>\n",
       "      <td>0.844743</td>\n",
       "      <td>1.193585</td>\n",
       "      <td>453.596721</td>\n",
       "      <td>22.412081</td>\n",
       "      <td>1.214079</td>\n",
       "      <td>1.816763</td>\n",
       "      <td>22.064922</td>\n",
       "      <td>1.264982</td>\n",
       "      <td>1.816611</td>\n",
       "      <td>32.894693</td>\n",
       "      <td>1.812223</td>\n",
       "      <td>126.499506</td>\n",
       "      <td>0.977426</td>\n",
       "      <td>532.962789</td>\n",
       "      <td>489.338286</td>\n",
       "      <td>489.333883</td>\n",
       "      <td>479.875496</td>\n",
       "      <td>453.384624</td>\n",
       "      <td>453.389017</td>\n",
       "      <td>98.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.104000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>-1.414000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-2.499000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>-2.505000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>13.678000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>162499.750000</td>\n",
       "      <td>78.100750</td>\n",
       "      <td>19.241000</td>\n",
       "      <td>59.388750</td>\n",
       "      <td>14.068750</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.841000</td>\n",
       "      <td>77.550000</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>-1.371000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>24.591750</td>\n",
       "      <td>-0.925000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>32.375000</td>\n",
       "      <td>-1.014000</td>\n",
       "      <td>-1.522000</td>\n",
       "      <td>21.398000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>123.017500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>224999.500000</td>\n",
       "      <td>105.012000</td>\n",
       "      <td>46.524000</td>\n",
       "      <td>73.752000</td>\n",
       "      <td>38.467500</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2.491500</td>\n",
       "      <td>12.315500</td>\n",
       "      <td>120.664500</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>31.804000</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>40.516000</td>\n",
       "      <td>-0.045000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>34.802000</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>179.739000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.960000</td>\n",
       "      <td>-1.872000</td>\n",
       "      <td>-2.093000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>40.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>287499.250000</td>\n",
       "      <td>130.606250</td>\n",
       "      <td>73.598000</td>\n",
       "      <td>92.259000</td>\n",
       "      <td>79.169000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>83.446000</td>\n",
       "      <td>-4.593000</td>\n",
       "      <td>2.961000</td>\n",
       "      <td>27.591000</td>\n",
       "      <td>200.478250</td>\n",
       "      <td>1.777000</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.017000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>1.565000</td>\n",
       "      <td>53.390000</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>1.618000</td>\n",
       "      <td>51.895000</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>263.379250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>75.349000</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>33.703000</td>\n",
       "      <td>-2.457000</td>\n",
       "      <td>-2.275000</td>\n",
       "      <td>109.933750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>349999.000000</td>\n",
       "      <td>1192.026000</td>\n",
       "      <td>690.075000</td>\n",
       "      <td>1349.351000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>8.503000</td>\n",
       "      <td>4974.979000</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>1852.462000</td>\n",
       "      <td>19.773000</td>\n",
       "      <td>1.414000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>764.408000</td>\n",
       "      <td>2.497000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>560.271000</td>\n",
       "      <td>2.503000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2842.617000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2003.976000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1120.573000</td>\n",
       "      <td>4.499000</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>721.456000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>1633.433000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             EventId   DER_mass_MMC  ...  PRI_jet_subleading_phi  PRI_jet_all_pt\n",
       "count  250000.000000  250000.000000  ...           250000.000000   250000.000000\n",
       "mean   224999.500000     -49.023079  ...             -709.118631       73.064591\n",
       "std     72168.927986     406.345647  ...              453.389017       98.015662\n",
       "min    100000.000000    -999.000000  ...             -999.000000        0.000000\n",
       "25%    162499.750000      78.100750  ...             -999.000000        0.000000\n",
       "50%    224999.500000     105.012000  ...             -999.000000       40.512500\n",
       "75%    287499.250000     130.606250  ...               -2.275000      109.933750\n",
       "max    349999.000000    1192.026000  ...                3.142000     1633.433000\n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higgsData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nfLzzDygVxHH",
    "outputId": "a2066f39-5387-4f15-f529-9ef04e55ebbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['s', 'b', 'b', ..., 's', 'b', 'b'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oh_tkU-hV9pt",
    "outputId": "9eb12f34-547a-4f41-e49f-0e67be653b95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00265331, 2.23358449, 2.34738894, ..., 0.01863612, 1.68161144,\n",
       "       1.87747381])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "emrobofLWWhP"
   },
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_pC_3biq_xU"
   },
   "outputs": [],
   "source": [
    "# leave\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLK2qoS_oW_j"
   },
   "source": [
    "- Use a Random Forest and a Gradiend Boosted Tree Classifier model to predict the label of the particles. get the score of the model on the training and test set and comment on the result for each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Htf_qENzNNcV",
    "outputId": "c5606f11-5258-4331-d16e-2f7d56d939e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 'warn', 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#leave \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "# random_state parameter is the seed being used\n",
    "rf = RandomForestClassifier(random_state = 0)\n",
    "print('Parameters currently in use:\\n')\n",
    "print(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2eNZHaTYy89c"
   },
   "outputs": [],
   "source": [
    "gbt = GradientBoostingClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_HVPso8NcmUz"
   },
   "source": [
    "Note: training the models takes some time. Especially the gradient boosted method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lgj5GxoToYfU"
   },
   "outputs": [],
   "source": [
    "higgsData.reset_index(drop = True, inplace = True)\n",
    "trainData, testData = train_test_split(higgsData, train_size = 0.75, random_state = 0)\n",
    "rf.fit(trainData, labels[trainData.index]);\n",
    "gbt.fit(trainData, labels[trainData.index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3C_3_nhoPhQY"
   },
   "source": [
    "calculate the  scores for the training and test sets and evaluate  overtraining etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "1iEwXQLDaJpV",
    "outputId": "f989b814-4fc5-463a-df5b-839abf937187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Scores:\n",
      "    Training:\t98.79%\n",
      "    Test:\t82.34%\n",
      "\n",
      "Gradient Boosting Model Scores:\n",
      "    Training:\t83.35%\n",
      "    Test:\t83.25%\n"
     ]
    }
   ],
   "source": [
    "rfScore = (rf.score(trainData, labels[trainData.index]), rf.score(testData, labels[testData.index]))\n",
    "gbtScore = (gbt.score(trainData, labels[trainData.index]), gbt.score(testData, labels[testData.index]))\n",
    "\n",
    "print('Random Forest Model Scores:\\n    Training:\\t%.2f%%\\n    Test:\\t%.2f%%' % (100*rfScore[0], 100*rfScore[1]))\n",
    "print('\\nGradient Boosting Model Scores:\\n    Training:\\t%.2f%%\\n    Test:\\t%.2f%%' % (100*gbtScore[0], 100*gbtScore[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z9QCbOsy2_Zt"
   },
   "source": [
    "The Random Forest model had a much higher accuracy on the training data than on the test data. This implies that the model is overfitting the data.\n",
    "\n",
    "The Gradient Boosted model had very similar accuracies for the training and test data. This implies that the model is *not* overfitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvO21hbN5lXN"
   },
   "source": [
    "## Compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aiULt4TP8kn"
   },
   "source": [
    "- Produce a confusion matrix for each model and compare them\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ak3gnF6duviH"
   },
   "outputs": [],
   "source": [
    "\n",
    "# I created this function (mostly copied from sklearn examples). \n",
    "# You can use it to create the confusion matrix\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, normalize=False, title='', cmap=plt.cm.bone):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"         \n",
    "    if normalize:\n",
    "          title = title + ' Normalized confusion matrix'\n",
    "    else:\n",
    "          title = title + ' Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # plot it\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    fig.subplots_adjust()\n",
    "    im = ax.imshow(cm, cmap=cmap)\n",
    "    ax_divider = make_axes_locatable(ax)\n",
    "    # add an axes to the right of the main axes.\n",
    "    plt.xticks([0, 1], labels=[\"N\", \"P\"])\n",
    "    plt.ylim(-0.5,1.5)\n",
    "    plt.yticks([0,1], labels=[\"N\", \"P\"])    \n",
    "    plt.title(title)\n",
    "    cax = ax_divider.append_axes(\"right\", size=\"10%\", pad=\"2%\")\n",
    "    cb = plt.colorbar(im, cax=cax)\n",
    "\n",
    "def confusion_matrix_numbers(model, data):\n",
    "    predictP = model.predict(data) == 's'\n",
    "    actualP = labels[data.index] == 's'\n",
    "    predictN = model.predict(data) == 'b'\n",
    "    actualN = labels[data.index] == 'b'\n",
    "\n",
    "    PP = sum(predictP*actualP)\n",
    "    NP = sum(predictN*actualP)\n",
    "    NN = sum(predictN*actualN)\n",
    "    PN = sum(predictP*actualN)\n",
    "\n",
    "    print(tabulate([['NP: ' + str(NP), 'PP: ' + str(PP)], ['', ''], ['NN: ' + str(NN), 'PN: ' + str(PN)]]))\n",
    "    accuracy = (PP + NN) / (PP + NN + NP + PN)\n",
    "    print('The total accuracy of this model on the data is %.2f%%' % (100*accuracy))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "xQ-drA595_S8",
    "outputId": "7df1b871-2975-454c-d128-196c4afc4e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------  ---------\n",
      "NP: 7266   PP: 14118\n",
      "\n",
      "NN: 37344  PN: 3772\n",
      "---------  ---------\n",
      "The total accuracy of this model on the data is 82.34%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEICAYAAADGG5iAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n94DoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_true = labels[testData.index], y_pred = rf.predict(testData), title = 'RF')\n",
    "confusion_matrix_numbers(rf, testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbXjM8g-7oLD"
   },
   "source": [
    "**Figure 1:** The confusion matrix for the RF model shows that the model was fairly accurate. In this matrix, *P* corresponds to an *s* label and *N* corresponds to a *b* label.\n",
    "\n",
    "The *N-N* block is very white, meaning there were many instances (37,344) that were truly *b* that were correctly predicted to be *b*.\n",
    "\n",
    "The hue of the *P-P* block falls around the middle range of the colorbar (14,118). This is darker than the *N-N* block, which means there were less instances that were truly *s* that were correctly predicted to be *s*. However, there were more *b* instances overall.\n",
    "\n",
    "The *N-P* and *P-N* blocks are very dark. This means that there were very few instances (7,266 and 3,772) that were incorrectly predicted.\n",
    "\n",
    "**Overall, 82.34% of the labels were correctly predicted.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "zIjFmF7D7nFN",
    "outputId": "118cee30-4d6f-4908-c3c0-1d9c30412fdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------  ---------\n",
      "NP: 6227   PP: 15157\n",
      "\n",
      "NN: 36874  PN: 4242\n",
      "---------  ---------\n",
      "The total accuracy of this model on the data is 83.25%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEICAYAAADFrJaoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMwD+P+NnoUl5mL8JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_true = labels[testData.index], y_pred = rf.predict(testData), title = 'GBT')\n",
    "confusion_matrix_numbers(gbt, testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Hy7FGU4BOkm"
   },
   "source": [
    "**Figure 2:** The confusion matrix for the RF model shows that the model was fairly accurate. In this matrix, *P* corresponds to an *s* label and *N* corresponds to a *b* label.\n",
    "\n",
    "The *N-N* block is very white, meaning there were many instances (36,874) that were truly *b* that were correctly predicted to be *b*.\n",
    "\n",
    "The hue of the *P-P* block falls around the middle range of the colorbar (15,157\n",
    "). This is darker than the *N-N* block, which means there were less instances that were truly *s* that were correctly predicted to be *s*. However, there were more *b* instances overall.\n",
    "\n",
    "The *N-P* and *P-N* blocks are very dark. This means that there were very few instances (6,227 and 4,242) that were incorrectly predicted.\n",
    "\n",
    "**Overall, 83.25% of the labels were correctly predicted.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Di6R9nJRBObB"
   },
   "source": [
    "**Comparison**\n",
    "\n",
    "The random forest and gradient boosted models both had similar accuracy on the testing data. The random forest model had an accuracy of **82.34%** on the test data, while the gradient boosted model had a slightly higher accuracy of **83.25%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_kdHBj6DktY"
   },
   "source": [
    "## Predict the weights of the particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbZQ3kMSQFK6"
   },
   "source": [
    "\n",
    "- Use a Random Forest and a Gradiend Boosted Tree Regressor model to predict the weight of the particles. Compare the model performance on training and test setsm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5hyj7jdlKvT"
   },
   "outputs": [],
   "source": [
    "trainWeights, testWeights = weights[trainData.index], weights[testData.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_6uYj243Be_"
   },
   "outputs": [],
   "source": [
    "traindata_weights, testdata_weights, train_weights, test_weights = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "UkanVFfO3HBe",
    "outputId": "1cb527f1-b1e5-4f4a-d5c9-006029681eb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfR = RandomForestRegressor(n_estimators=100, max_depth=3, random_state=0)\n",
    "rfR.fit(trainData, trainWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "oYbj9dPbmISL",
    "outputId": "e4be4376-6cf4-40b9-d233-bf2ab7b3c3a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto', random_state=0,\n",
       "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "                          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbtR = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=0)\n",
    "gbtR.fit(trainData, trainWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKvyqcFr3Z3d"
   },
   "source": [
    "Calculate the L2 and L1 loss functions for the fitted regression models (see slides for the definition) and discuss the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "020fzW2OnsZF",
    "outputId": "dd1f0a3a-ff00-4157-e080-1869988e9c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Method: \n",
      "L1: \t62814 \n",
      "L2: \t114399\n",
      "\n",
      "Gradient Boosting Method: \n",
      "L1: \t52788 \n",
      "L2: \t85175\n"
     ]
    }
   ],
   "source": [
    "L1 = sum(abs(testWeights - rfR.predict(testData)))\n",
    "L2 = sum((testWeights - rfR.predict(testData))**2)\n",
    "print('Random Forest Method: \\nL1: \\t%d \\nL2: \\t%d' % (L1, L2))\n",
    "\n",
    "L1 = sum(abs(testWeights - gbtR.predict(testData)))\n",
    "L2 = sum((testWeights - gbtR.predict(testData))**2)\n",
    "print('\\nGradient Boosting Method: \\nL1: \\t%d \\nL2: \\t%d' % (L1, L2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ggz2O7u12Kai"
   },
   "source": [
    "The losses for the Gradient Boosting Method were smaller than the losses for the Random Forest Method. This implies that the GBT method is more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-G29xXSD2N1o"
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c38At7ayYd_5"
   },
   "source": [
    "- For the Random Forest classifier, find the 4 most important features based on the simple unoptimized model you created earlier on. Use the documentation to find out what they are. We have not talked about the physics of this problem at all but the Kaggle challenge description should provide enogh information for you to comment on this result is somewhat superficially.\n",
    "\n",
    "You can use ```rf.feature_importance_``` on the trained model to extract the relative importance of each feature (a number from 0 to 1) and then choose the features that have the 4 highest numbers (the numpy function ```argsort()``` is helpful here!)\n",
    "\n",
    "Explore the parameter space with the sklearn module ```sklearn.model_selection.RandomizedSearchCV``` *fitting only those 4 features*\n",
    "\n",
    "Follow this example to set up the parameter search. Set the estimators to 10 and 100, (the number of trees) and the max depth to 3, and 10, and None (let it be unconstrained). Set bootstrap to both True and False. Set the number of features to consider at every split to both \"auto\" and \"sqrt\". Use ```pprint``` like I did earlier in this notebook to print the parameters set\n",
    "\n",
    "**this takes some computational time! so do not start this at the last minute!!**\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "dmTsSSEUqO2G",
    "outputId": "eb72249f-c218-4322-e34e-f0239f0c83fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  DER_mass_MMC:\t 0.16\n",
      "   DER_mass_transverse_met_lep:\t 0.11\n",
      "                  DER_mass_vis:\t 0.07\n",
      "                    PRI_tau_pt:\t 0.06\n"
     ]
    }
   ],
   "source": [
    "importances = [(i, j) for i, j in zip(trainData.columns, rf.feature_importances_)]\n",
    "importances.sort(key = lambda x: x[1], reverse = True)\n",
    "for i in range(4):\n",
    "  print(\"%30.30s:\\t %.2f\" % importances[i])\n",
    "bestFeatures = [importances[i][0] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-QQqGlp5ty3"
   },
   "outputs": [],
   "source": [
    "random_grid = {'max_depth': [3, 10, None], 'max_features': ['auto', 'sqrt'], 'n_estimators': [10, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfdKk4Pk7tTz"
   },
   "source": [
    " mine and your best features do not necessarily have to be the same because our models may be different (different parameters, different random seed etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "qmyw7x3EwTrz",
    "outputId": "5feeb728-1f62-469d-d339-93ff060a059f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>PRI_tau_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>32.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>42.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>32.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>22.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>28.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>-999.000</td>\n",
       "      <td>71.989</td>\n",
       "      <td>36.548</td>\n",
       "      <td>24.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>-999.000</td>\n",
       "      <td>58.179</td>\n",
       "      <td>68.083</td>\n",
       "      <td>23.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>105.457</td>\n",
       "      <td>60.526</td>\n",
       "      <td>75.839</td>\n",
       "      <td>35.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>94.951</td>\n",
       "      <td>19.362</td>\n",
       "      <td>68.812</td>\n",
       "      <td>27.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>-999.000</td>\n",
       "      <td>72.756</td>\n",
       "      <td>70.831</td>\n",
       "      <td>43.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  PRI_tau_pt\n",
       "0            138.470                       51.655        97.827      32.638\n",
       "1            160.937                       68.768       103.235      42.014\n",
       "2           -999.000                      162.172       125.953      32.154\n",
       "3            143.905                       81.417        80.943      22.647\n",
       "4            175.864                       16.915       134.805      28.209\n",
       "...              ...                          ...           ...         ...\n",
       "249995      -999.000                       71.989        36.548      24.754\n",
       "249996      -999.000                       58.179        68.083      23.416\n",
       "249997       105.457                       60.526        75.839      35.636\n",
       "249998        94.951                       19.362        68.812      27.944\n",
       "249999      -999.000                       72.756        70.831      43.003\n",
       "\n",
       "[250000 rows x 4 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higgsData[bestFeatures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T3W60KM1Jb5r"
   },
   "source": [
    "Note that this may take a long time! It took 1 hour for me to run this. Dont start at the last minute!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1AJ70oqZPvL_",
    "outputId": "f55c756b-bb44-4fac-e9eb-6308ac461751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned RF  Parameters: DER_mass_MMC, DER_mass_transverse_met_lep, DER_mass_vis, PRI_tau_pt\n",
      "Best score is 0.7968\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 18 different combinations\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = rf, param_distributions=random_grid, n_iter=1, cv=3, iid=False)\n",
    "random_search.fit(higgsData[bestFeatures], labels);\n",
    "\n",
    "scores = random_search.cv_results_['split0_test_score'][0], random_search.cv_results_['split1_test_score'][0], random_search.cv_results_['split2_test_score'][0]\n",
    "print(\"Tuned RF  Parameters: %s, %s, %s, %s\" % (bestFeatures[0], bestFeatures[1], bestFeatures[2], bestFeatures[3]))\n",
    "print(\"Best score is %.4f\" % max(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**-2.5 pts: Tuned RF parameters is not the most important columns, it is the best parameters for RF model which means best max_depth, max_feature, etc.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "WaHvlFa27EV4",
    "outputId": "22d23f79-790c-42ae-d38b-b28b881b6148"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.513457</td>\n",
       "      <td>0.313391</td>\n",
       "      <td>0.650082</td>\n",
       "      <td>0.018376</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_estimators': 100, 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.795954</td>\n",
       "      <td>0.793734</td>\n",
       "      <td>0.796777</td>\n",
       "      <td>0.795488</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "0      12.513457      0.313391  ...        0.001285                1\n",
       "\n",
       "[1 rows x 14 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "<span style=\"color:red\">**-2.5 pts: Tuned RF parameters is not the most important columns, it is the best parameters for RF model which means best max_depth, max_feature, etc.**</span>df = pd.DataFrame(random_search.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1r9zN9yI-at"
   },
   "source": [
    "# Plot a simple 3-point ROC curve for the model with the best parameters found in the previous step. Describe it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wl2NKYAy9LYt"
   },
   "outputs": [],
   "source": [
    "rf.fit(trainData, labels[trainData.index].flatten()==\"s\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "Re9hOoJgC-L9",
    "outputId": "4b791d71-dd4e-418b-cb07-cc71d4b5b3c6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The random forest model by itself\n",
    "from sklearn.metrics import roc_curve\n",
    "y_pred_grd_rfcat = rf.predict_proba(testData)[:, 1]\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(labels[testData.index].flatten()==\"s\", rf.predict(testData))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e5C2AhzMDXyd"
   },
   "source": [
    "**Figure 3:** The ROC curve shows the trade-off between sensitivity (or TPR) and specificity (1 – FPR). In an ROC curve chart, a model is shown to be more accurate if it hugs the left axis moreso than it hugs the 45 degree line.\n",
    "\n",
    "This figure depicts the model having a steep increase at the beginning before flattening out."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "higgsbosonSearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
