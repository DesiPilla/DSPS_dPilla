{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "higgsbosonSearch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DesiPilla/DSPS_dPilla/blob/master/HW9/higgsbosonSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwvk8bzJUv-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xpw06PzTsU6",
        "colab_type": "code",
        "outputId": "697e9627-78a3-484b-e24e-93059e7e2102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1JoRqCoDVqK",
        "colab_type": "text"
      },
      "source": [
        "## Download Data from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS4S7msAPK_R",
        "colab_type": "text"
      },
      "source": [
        "- Download the Higgs boson data from Kaggle (programmatically within the notebook)\n",
        "see how I did it in the Titanic Trees notebook https://github.com/fedhere/DSPS/blob/master/lab9/titanictree.ipynb\n",
        "\n",
        "find the correct API link here https://www.kaggle.com/c/higgs-boson/data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MP1xlkGDVRD",
        "colab_type": "code",
        "outputId": "dd200335-b41f-4081-e1aa-5ebb509b3650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "pip install kaggle"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.9.11)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiDVRqzFDdNO",
        "colab_type": "code",
        "outputId": "766fd803-2173-4c7d-b03a-27b36821e086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd 'drive/My Drive/dsps'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dsps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyY2jIhUEYKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKT3A0JoJr-P",
        "colab_type": "code",
        "outputId": "38bd8a74-e92f-4834-cb26-6841963600f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/     \u001b[01;34mkaggleHiggsBoson\u001b[0m/           pluto_18v2_1.csv\n",
            "data.csv  nyc_pluto_18v2_1_csv.zip    PLUTODD18v2.1.pdf\n",
            "\u001b[01;34mkaggle\u001b[0m/   nyc_pluto_18v2_1_csv.zip.1  PlutoReadme18v2.1.pdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyjFZTOIJZq3",
        "colab_type": "code",
        "outputId": "91e2ef5c-111c-49f7-83f9-f81524b7e05f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd kaggle"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dsps/kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsc_AS2kHlp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp kaggle.json ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ-WvVSBFLS3",
        "colab_type": "code",
        "outputId": "76c1dc9f-0788-4380-849d-7e4d9eebf681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls ~/.kaggle"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOCbU-UvJ52X",
        "colab_type": "code",
        "outputId": "ec489a95-86c2-4ce6-9797-8ef39d58e38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd ~/.kaggle"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovLEgJSHI6AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC2Z2KVWKFmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "envs = json.load(open(\"kaggle.json\", \"r\"))\n",
        "os.environ[\"catherineharty\"] = envs['username']\n",
        "os.environ[\"824253b26696e60f3f970caa98c670cf\"] = envs['key']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I01rJB5BKTeY",
        "colab_type": "code",
        "outputId": "38654523-dd73-4133-f6c8-e3ef36c7b6e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '../../content/drive/My Drive/dsps'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dsps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VlK0pL1K1Gw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a666510-8b58-4097-8041-01be89dbc97c"
      },
      "source": [
        "!mkdir kaggleHiggsBoson"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘kaggleHiggsBoson’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEU-FLt8K7UE",
        "colab_type": "code",
        "outputId": "eb30c90b-2726-4afe-9a58-9e9d03517097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd kaggleHiggsBoson"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dsps/kaggleHiggsBoson\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO6iBjzCK9Rx",
        "colab_type": "code",
        "outputId": "22b87485-5bea-49d6-e9ea-e505a3d3377b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                      title                                               size  lastUpdated          downloadCount  \n",
            "-------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "tristan581/17k-apple-app-store-strategy-games            17K Mobile Strategy Games                            8MB  2019-08-26 08:22:16          10302  \n",
            "gustavomodelli/forest-fires-in-brazil                    Forest Fires in Brazil                              31KB  2019-08-24 16:09:16          11335  \n",
            "akhilv11/border-crossing-entry-data                      Border Crossing Entry Data                           4MB  2019-08-21 14:51:34           4892  \n",
            "rajeevw/ufcdata                                          UFC-Fight historical data from 1993 to 2019          3MB  2019-07-05 09:58:02           5841  \n",
            "shuyangli94/food-com-recipes-and-user-interactions       Food.com Recipes and Interactions                  267MB  2019-10-12 06:30:37           3303  \n",
            "chirin/africa-economic-banking-and-systemic-crisis-data  Africa Economic, Banking and Systemic Crisis Data   14KB  2019-07-21 02:00:17           3687  \n",
            "ruslankl/european-union-lgbt-survey-2012                 EU LGBT Survey                                     610KB  2019-07-19 11:15:25           1587  \n",
            "kapilverma/hindi-bible                                   Hindi Bible                                          5MB  2019-09-07 18:04:35            324  \n",
            "jojoker/singapore-airbnb                                 Singapore Airbnb                                   350KB  2019-09-25 22:05:44           1980  \n",
            "hmavrodiev/sofia-air-quality-dataset                     Sofia air quality dataset                            3GB  2019-09-14 05:48:09           1288  \n",
            "mabusalah/brent-oil-prices                               Brent Oil Prices                                    38KB  2019-10-14 12:31:05           1420  \n",
            "nitinsss/military-expenditure-of-countries-19602019      Military Spending of Countries (1960-2019)          55KB  2019-10-10 12:17:37           2577  \n",
            "irinachuchueva/russian-wholesale-electricity-market      Russian Wholesale Electricity Market                 1MB  2019-10-09 08:20:57            551  \n",
            "smid80/canadian-federal-election-results-timeseries      Canadian Federal Election Results (Timeseries)      18MB  2019-10-09 11:08:29            581  \n",
            "brkurzawa/us-breweries                                   US Breweries                                        76KB  2019-10-02 03:15:27           1646  \n",
            "srikantsahu/co2-and-ghg-emission-data                    CO2 and GHG emission data                           91KB  2019-09-26 20:10:59           1574  \n",
            "pascalbliem/european-social-survey-ess-8-ed21-201617     European Social Survey (ESS) 8 ed2.1 (2016/17)      10MB  2019-09-29 07:30:37            589  \n",
            "grikomsn/amazon-cell-phones-reviews                      Amazon Cell Phones Reviews                          10MB  2019-09-29 02:26:48           2221  \n",
            "valentynsichkar/traffic-signs-preprocessed               Traffic Signs Preprocessed                            0B  2019-08-31 18:22:11           1217  \n",
            "hmavrodiev/london-bike-sharing-dataset                   London bike sharing dataset                        165KB  2019-10-10 12:49:37           2746  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPeW-pjDUhsp",
        "colab_type": "text"
      },
      "source": [
        "In order to download the data, I had to accept the rules and verify my account on kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_GgS2XtFEVc",
        "colab_type": "code",
        "outputId": "29130d00-cca6-4743-edf6-4b2a2d004575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!kaggle competitions download -c higgs-boson"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "random_submission.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "training.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "HiggsBosonCompetition_AMSMetric_rev1.py: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7-UQVjpLVcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "da4b55ff-4aa5-49f9-d574-12170adb7372"
      },
      "source": [
        "ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HiggsBosonCompetition_AMSMetric_rev1.py  test.zip      training.zip\n",
            "random_submission.zip                    training.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n01LzGYWMGW",
        "colab_type": "text"
      },
      "source": [
        "## Prepare training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMuvMJgOnlYo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "- Read in the training data. Split the provided training data into a training and a test set. \n",
        "The last 2 columns are what you want to predict: \"weight\" and \"label\".\n",
        "Remove them from the input data and create a separate variable label and a separate variable weight, which will be your target variables for, respectively, classification and regression.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83TI5ZHIEIqU",
        "colab_type": "code",
        "outputId": "28735454-535a-441e-e7c2-26a0064ff557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!unzip training.zip"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  training.zip\n",
            "replace training.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: training.csv            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQThom3HUraF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "466746b3-18e9-4df7-b48a-0dc635072c38"
      },
      "source": [
        "higgsData = pd.read_csv('training.csv')\n",
        "weights = higgsData['Weight'].values\n",
        "labels = higgsData['Label'].values\n",
        "higgsData.drop(columns = ['Weight', 'Label'], inplace = True)\n",
        "\n",
        "higgsData.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EventId</th>\n",
              "      <th>DER_mass_MMC</th>\n",
              "      <th>DER_mass_transverse_met_lep</th>\n",
              "      <th>DER_mass_vis</th>\n",
              "      <th>DER_pt_h</th>\n",
              "      <th>DER_deltaeta_jet_jet</th>\n",
              "      <th>DER_mass_jet_jet</th>\n",
              "      <th>DER_prodeta_jet_jet</th>\n",
              "      <th>DER_deltar_tau_lep</th>\n",
              "      <th>DER_pt_tot</th>\n",
              "      <th>DER_sum_pt</th>\n",
              "      <th>DER_pt_ratio_lep_tau</th>\n",
              "      <th>DER_met_phi_centrality</th>\n",
              "      <th>DER_lep_eta_centrality</th>\n",
              "      <th>PRI_tau_pt</th>\n",
              "      <th>PRI_tau_eta</th>\n",
              "      <th>PRI_tau_phi</th>\n",
              "      <th>PRI_lep_pt</th>\n",
              "      <th>PRI_lep_eta</th>\n",
              "      <th>PRI_lep_phi</th>\n",
              "      <th>PRI_met</th>\n",
              "      <th>PRI_met_phi</th>\n",
              "      <th>PRI_met_sumet</th>\n",
              "      <th>PRI_jet_num</th>\n",
              "      <th>PRI_jet_leading_pt</th>\n",
              "      <th>PRI_jet_leading_eta</th>\n",
              "      <th>PRI_jet_leading_phi</th>\n",
              "      <th>PRI_jet_subleading_pt</th>\n",
              "      <th>PRI_jet_subleading_eta</th>\n",
              "      <th>PRI_jet_subleading_phi</th>\n",
              "      <th>PRI_jet_all_pt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100000</td>\n",
              "      <td>138.470</td>\n",
              "      <td>51.655</td>\n",
              "      <td>97.827</td>\n",
              "      <td>27.980</td>\n",
              "      <td>0.91</td>\n",
              "      <td>124.711</td>\n",
              "      <td>2.666</td>\n",
              "      <td>3.064</td>\n",
              "      <td>41.928</td>\n",
              "      <td>197.760</td>\n",
              "      <td>1.582</td>\n",
              "      <td>1.396</td>\n",
              "      <td>0.2</td>\n",
              "      <td>32.638</td>\n",
              "      <td>1.017</td>\n",
              "      <td>0.381</td>\n",
              "      <td>51.626</td>\n",
              "      <td>2.273</td>\n",
              "      <td>-2.414</td>\n",
              "      <td>16.824</td>\n",
              "      <td>-0.277</td>\n",
              "      <td>258.733</td>\n",
              "      <td>2</td>\n",
              "      <td>67.435</td>\n",
              "      <td>2.150</td>\n",
              "      <td>0.444</td>\n",
              "      <td>46.062</td>\n",
              "      <td>1.24</td>\n",
              "      <td>-2.475</td>\n",
              "      <td>113.497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100001</td>\n",
              "      <td>160.937</td>\n",
              "      <td>68.768</td>\n",
              "      <td>103.235</td>\n",
              "      <td>48.146</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>3.473</td>\n",
              "      <td>2.078</td>\n",
              "      <td>125.157</td>\n",
              "      <td>0.879</td>\n",
              "      <td>1.414</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>42.014</td>\n",
              "      <td>2.039</td>\n",
              "      <td>-3.011</td>\n",
              "      <td>36.918</td>\n",
              "      <td>0.501</td>\n",
              "      <td>0.103</td>\n",
              "      <td>44.704</td>\n",
              "      <td>-1.916</td>\n",
              "      <td>164.546</td>\n",
              "      <td>1</td>\n",
              "      <td>46.226</td>\n",
              "      <td>0.725</td>\n",
              "      <td>1.158</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>46.226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100002</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>162.172</td>\n",
              "      <td>125.953</td>\n",
              "      <td>35.635</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>3.148</td>\n",
              "      <td>9.336</td>\n",
              "      <td>197.814</td>\n",
              "      <td>3.776</td>\n",
              "      <td>1.414</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>32.154</td>\n",
              "      <td>-0.705</td>\n",
              "      <td>-2.093</td>\n",
              "      <td>121.409</td>\n",
              "      <td>-0.953</td>\n",
              "      <td>1.052</td>\n",
              "      <td>54.283</td>\n",
              "      <td>-2.186</td>\n",
              "      <td>260.414</td>\n",
              "      <td>1</td>\n",
              "      <td>44.251</td>\n",
              "      <td>2.053</td>\n",
              "      <td>-2.028</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>44.251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100003</td>\n",
              "      <td>143.905</td>\n",
              "      <td>81.417</td>\n",
              "      <td>80.943</td>\n",
              "      <td>0.414</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>3.310</td>\n",
              "      <td>0.414</td>\n",
              "      <td>75.968</td>\n",
              "      <td>2.354</td>\n",
              "      <td>-1.285</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>22.647</td>\n",
              "      <td>-1.655</td>\n",
              "      <td>0.010</td>\n",
              "      <td>53.321</td>\n",
              "      <td>-0.522</td>\n",
              "      <td>-3.100</td>\n",
              "      <td>31.082</td>\n",
              "      <td>0.060</td>\n",
              "      <td>86.062</td>\n",
              "      <td>0</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100004</td>\n",
              "      <td>175.864</td>\n",
              "      <td>16.915</td>\n",
              "      <td>134.805</td>\n",
              "      <td>16.405</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>3.891</td>\n",
              "      <td>16.405</td>\n",
              "      <td>57.983</td>\n",
              "      <td>1.056</td>\n",
              "      <td>-1.385</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>28.209</td>\n",
              "      <td>-2.197</td>\n",
              "      <td>-2.231</td>\n",
              "      <td>29.774</td>\n",
              "      <td>0.798</td>\n",
              "      <td>1.569</td>\n",
              "      <td>2.723</td>\n",
              "      <td>-0.871</td>\n",
              "      <td>53.131</td>\n",
              "      <td>0</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   EventId  DER_mass_MMC  ...  PRI_jet_subleading_phi  PRI_jet_all_pt\n",
              "0   100000       138.470  ...                  -2.475         113.497\n",
              "1   100001       160.937  ...                -999.000          46.226\n",
              "2   100002      -999.000  ...                -999.000          44.251\n",
              "3   100003       143.905  ...                -999.000          -0.000\n",
              "4   100004       175.864  ...                -999.000           0.000\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjYc20zgVgaU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "680c8189-b1d5-49b6-8850-90c9983de2c8"
      },
      "source": [
        "higgsData.describe()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EventId</th>\n",
              "      <th>DER_mass_MMC</th>\n",
              "      <th>DER_mass_transverse_met_lep</th>\n",
              "      <th>DER_mass_vis</th>\n",
              "      <th>DER_pt_h</th>\n",
              "      <th>DER_deltaeta_jet_jet</th>\n",
              "      <th>DER_mass_jet_jet</th>\n",
              "      <th>DER_prodeta_jet_jet</th>\n",
              "      <th>DER_deltar_tau_lep</th>\n",
              "      <th>DER_pt_tot</th>\n",
              "      <th>DER_sum_pt</th>\n",
              "      <th>DER_pt_ratio_lep_tau</th>\n",
              "      <th>DER_met_phi_centrality</th>\n",
              "      <th>DER_lep_eta_centrality</th>\n",
              "      <th>PRI_tau_pt</th>\n",
              "      <th>PRI_tau_eta</th>\n",
              "      <th>PRI_tau_phi</th>\n",
              "      <th>PRI_lep_pt</th>\n",
              "      <th>PRI_lep_eta</th>\n",
              "      <th>PRI_lep_phi</th>\n",
              "      <th>PRI_met</th>\n",
              "      <th>PRI_met_phi</th>\n",
              "      <th>PRI_met_sumet</th>\n",
              "      <th>PRI_jet_num</th>\n",
              "      <th>PRI_jet_leading_pt</th>\n",
              "      <th>PRI_jet_leading_eta</th>\n",
              "      <th>PRI_jet_leading_phi</th>\n",
              "      <th>PRI_jet_subleading_pt</th>\n",
              "      <th>PRI_jet_subleading_eta</th>\n",
              "      <th>PRI_jet_subleading_phi</th>\n",
              "      <th>PRI_jet_all_pt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>224999.500000</td>\n",
              "      <td>-49.023079</td>\n",
              "      <td>49.239819</td>\n",
              "      <td>81.181982</td>\n",
              "      <td>57.895962</td>\n",
              "      <td>-708.420675</td>\n",
              "      <td>-601.237051</td>\n",
              "      <td>-709.356603</td>\n",
              "      <td>2.373100</td>\n",
              "      <td>18.917332</td>\n",
              "      <td>158.432217</td>\n",
              "      <td>1.437609</td>\n",
              "      <td>-0.128305</td>\n",
              "      <td>-708.985189</td>\n",
              "      <td>38.707419</td>\n",
              "      <td>-0.010973</td>\n",
              "      <td>-0.008171</td>\n",
              "      <td>46.660207</td>\n",
              "      <td>-0.019507</td>\n",
              "      <td>0.043543</td>\n",
              "      <td>41.717235</td>\n",
              "      <td>-0.010119</td>\n",
              "      <td>209.797178</td>\n",
              "      <td>0.979176</td>\n",
              "      <td>-348.329567</td>\n",
              "      <td>-399.254314</td>\n",
              "      <td>-399.259788</td>\n",
              "      <td>-692.381204</td>\n",
              "      <td>-709.121609</td>\n",
              "      <td>-709.118631</td>\n",
              "      <td>73.064591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>72168.927986</td>\n",
              "      <td>406.345647</td>\n",
              "      <td>35.344886</td>\n",
              "      <td>40.828691</td>\n",
              "      <td>63.655682</td>\n",
              "      <td>454.480565</td>\n",
              "      <td>657.972302</td>\n",
              "      <td>453.019877</td>\n",
              "      <td>0.782911</td>\n",
              "      <td>22.273494</td>\n",
              "      <td>115.706115</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>1.193585</td>\n",
              "      <td>453.596721</td>\n",
              "      <td>22.412081</td>\n",
              "      <td>1.214079</td>\n",
              "      <td>1.816763</td>\n",
              "      <td>22.064922</td>\n",
              "      <td>1.264982</td>\n",
              "      <td>1.816611</td>\n",
              "      <td>32.894693</td>\n",
              "      <td>1.812223</td>\n",
              "      <td>126.499506</td>\n",
              "      <td>0.977426</td>\n",
              "      <td>532.962789</td>\n",
              "      <td>489.338286</td>\n",
              "      <td>489.333883</td>\n",
              "      <td>479.875496</td>\n",
              "      <td>453.384624</td>\n",
              "      <td>453.389017</td>\n",
              "      <td>98.015662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>100000.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.329000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>0.208000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.104000</td>\n",
              "      <td>0.047000</td>\n",
              "      <td>-1.414000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>-2.499000</td>\n",
              "      <td>-3.142000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>-2.505000</td>\n",
              "      <td>-3.142000</td>\n",
              "      <td>0.109000</td>\n",
              "      <td>-3.142000</td>\n",
              "      <td>13.678000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>162499.750000</td>\n",
              "      <td>78.100750</td>\n",
              "      <td>19.241000</td>\n",
              "      <td>59.388750</td>\n",
              "      <td>14.068750</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>1.810000</td>\n",
              "      <td>2.841000</td>\n",
              "      <td>77.550000</td>\n",
              "      <td>0.883000</td>\n",
              "      <td>-1.371000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>24.591750</td>\n",
              "      <td>-0.925000</td>\n",
              "      <td>-1.575000</td>\n",
              "      <td>32.375000</td>\n",
              "      <td>-1.014000</td>\n",
              "      <td>-1.522000</td>\n",
              "      <td>21.398000</td>\n",
              "      <td>-1.575000</td>\n",
              "      <td>123.017500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>224999.500000</td>\n",
              "      <td>105.012000</td>\n",
              "      <td>46.524000</td>\n",
              "      <td>73.752000</td>\n",
              "      <td>38.467500</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>2.491500</td>\n",
              "      <td>12.315500</td>\n",
              "      <td>120.664500</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>-0.356000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>31.804000</td>\n",
              "      <td>-0.023000</td>\n",
              "      <td>-0.033000</td>\n",
              "      <td>40.516000</td>\n",
              "      <td>-0.045000</td>\n",
              "      <td>0.086000</td>\n",
              "      <td>34.802000</td>\n",
              "      <td>-0.024000</td>\n",
              "      <td>179.739000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>38.960000</td>\n",
              "      <td>-1.872000</td>\n",
              "      <td>-2.093000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>40.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>287499.250000</td>\n",
              "      <td>130.606250</td>\n",
              "      <td>73.598000</td>\n",
              "      <td>92.259000</td>\n",
              "      <td>79.169000</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>83.446000</td>\n",
              "      <td>-4.593000</td>\n",
              "      <td>2.961000</td>\n",
              "      <td>27.591000</td>\n",
              "      <td>200.478250</td>\n",
              "      <td>1.777000</td>\n",
              "      <td>1.225000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.017000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>1.565000</td>\n",
              "      <td>53.390000</td>\n",
              "      <td>0.959000</td>\n",
              "      <td>1.618000</td>\n",
              "      <td>51.895000</td>\n",
              "      <td>1.561000</td>\n",
              "      <td>263.379250</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>75.349000</td>\n",
              "      <td>0.433000</td>\n",
              "      <td>0.503000</td>\n",
              "      <td>33.703000</td>\n",
              "      <td>-2.457000</td>\n",
              "      <td>-2.275000</td>\n",
              "      <td>109.933750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>349999.000000</td>\n",
              "      <td>1192.026000</td>\n",
              "      <td>690.075000</td>\n",
              "      <td>1349.351000</td>\n",
              "      <td>2834.999000</td>\n",
              "      <td>8.503000</td>\n",
              "      <td>4974.979000</td>\n",
              "      <td>16.690000</td>\n",
              "      <td>5.684000</td>\n",
              "      <td>2834.999000</td>\n",
              "      <td>1852.462000</td>\n",
              "      <td>19.773000</td>\n",
              "      <td>1.414000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>764.408000</td>\n",
              "      <td>2.497000</td>\n",
              "      <td>3.142000</td>\n",
              "      <td>560.271000</td>\n",
              "      <td>2.503000</td>\n",
              "      <td>3.142000</td>\n",
              "      <td>2842.617000</td>\n",
              "      <td>3.142000</td>\n",
              "      <td>2003.976000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1120.573000</td>\n",
              "      <td>4.499000</td>\n",
              "      <td>3.141000</td>\n",
              "      <td>721.456000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>3.142000</td>\n",
              "      <td>1633.433000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             EventId   DER_mass_MMC  ...  PRI_jet_subleading_phi  PRI_jet_all_pt\n",
              "count  250000.000000  250000.000000  ...           250000.000000   250000.000000\n",
              "mean   224999.500000     -49.023079  ...             -709.118631       73.064591\n",
              "std     72168.927986     406.345647  ...              453.389017       98.015662\n",
              "min    100000.000000    -999.000000  ...             -999.000000        0.000000\n",
              "25%    162499.750000      78.100750  ...             -999.000000        0.000000\n",
              "50%    224999.500000     105.012000  ...             -999.000000       40.512500\n",
              "75%    287499.250000     130.606250  ...               -2.275000      109.933750\n",
              "max    349999.000000    1192.026000  ...                3.142000     1633.433000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfLzzDygVxHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2066f39-5387-4f15-f529-9ef04e55ebbb"
      },
      "source": [
        "labels"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['s', 'b', 'b', ..., 's', 'b', 'b'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh_tkU-hV9pt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9eb12f34-547a-4f41-e49f-0e67be653b95"
      },
      "source": [
        "weights"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00265331, 2.23358449, 2.34738894, ..., 0.01863612, 1.68161144,\n",
              "       1.87747381])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emrobofLWWhP",
        "colab_type": "text"
      },
      "source": [
        "## Create models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_pC_3biq_xU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# leave\n",
        "from sklearn.model_selection import train_test_split "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLK2qoS_oW_j",
        "colab_type": "text"
      },
      "source": [
        "- Use a Random Forest and a Gradiend Boosted Tree Classifier model to predict the label of the particles. get the score of the model on the training and test set and comment on the result for each model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htf_qENzNNcV",
        "colab_type": "code",
        "outputId": "c5606f11-5258-4331-d16e-2f7d56d939e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#leave \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Look at parameters used by our current forest\n",
        "# random_state parameter is the seed being used\n",
        "rf = RandomForestClassifier(random_state = 0)\n",
        "print('Parameters currently in use:\\n')\n",
        "print(rf.get_params())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 'warn', 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eNZHaTYy89c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbt = GradientBoostingClassifier(random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HVPso8NcmUz",
        "colab_type": "text"
      },
      "source": [
        "Note: training the models takes some time. Especially the gradient boosted method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgj5GxoToYfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "higgsData.reset_index(drop = True, inplace = True)\n",
        "trainData, testData = train_test_split(higgsData, train_size = 0.75, random_state = 0)\n",
        "rf.fit(trainData, labels[trainData.index]);\n",
        "gbt.fit(trainData, labels[trainData.index]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C_3_nhoPhQY",
        "colab_type": "text"
      },
      "source": [
        "calculate the  scores for the training and test sets and evaluate  overtraining etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iEwXQLDaJpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f989b814-4fc5-463a-df5b-839abf937187"
      },
      "source": [
        "rfScore = (rf.score(trainData, labels[trainData.index]), rf.score(testData, labels[testData.index]))\n",
        "gbtScore = (gbt.score(trainData, labels[trainData.index]), gbt.score(testData, labels[testData.index]))\n",
        "\n",
        "print('Random Forest Model Scores:\\n    Training:\\t%.2f%%\\n    Test:\\t%.2f%%' % (100*rfScore[0], 100*rfScore[1]))\n",
        "print('\\nGradient Boosting Model Scores:\\n    Training:\\t%.2f%%\\n    Test:\\t%.2f%%' % (100*gbtScore[0], 100*gbtScore[1]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Model Scores:\n",
            "    Training:\t98.79%\n",
            "    Test:\t82.34%\n",
            "\n",
            "Gradient Boosting Model Scores:\n",
            "    Training:\t83.35%\n",
            "    Test:\t83.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9QCbOsy2_Zt",
        "colab_type": "text"
      },
      "source": [
        "The Random Forest model had a much higher accuracy on the training data than on the test data. This implies that the model is overfitting the data.\n",
        "\n",
        "The Gradient Boosted model had very similar accuracies for the training and test data. This implies that the model is *not* overfitting the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvO21hbN5lXN",
        "colab_type": "text"
      },
      "source": [
        "## Compare models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aiULt4TP8kn",
        "colab_type": "text"
      },
      "source": [
        "- Produce a confusion matrix for each model and compare them\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak3gnF6duviH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# I created this function (mostly copied from sklearn examples). \n",
        "# You can use it to create the confusion matrix\n",
        "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, normalize=False, title='', cmap=plt.cm.bone):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"         \n",
        "    if normalize:\n",
        "          title = title + ' Normalized confusion matrix'\n",
        "    else:\n",
        "          title = title + ' Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # plot it\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    fig.subplots_adjust()\n",
        "    im = ax.imshow(cm, cmap=cmap)\n",
        "    ax_divider = make_axes_locatable(ax)\n",
        "    # add an axes to the right of the main axes.\n",
        "    plt.xticks([0, 1], labels=[\"N\", \"P\"])\n",
        "    plt.ylim(-0.5,1.5)\n",
        "    plt.yticks([0,1], labels=[\"N\", \"P\"])    \n",
        "    plt.title(title)\n",
        "    cax = ax_divider.append_axes(\"right\", size=\"10%\", pad=\"2%\")\n",
        "    cb = plt.colorbar(im, cax=cax)\n",
        "\n",
        "def confusion_matrix_numbers(model, data):\n",
        "    predictP = model.predict(data) == 's'\n",
        "    actualP = labels[data.index] == 's'\n",
        "    predictN = model.predict(data) == 'b'\n",
        "    actualN = labels[data.index] == 'b'\n",
        "\n",
        "    PP = sum(predictP*actualP)\n",
        "    NP = sum(predictN*actualP)\n",
        "    NN = sum(predictN*actualN)\n",
        "    PN = sum(predictP*actualN)\n",
        "\n",
        "    print(tabulate([['NP: ' + str(NP), 'PP: ' + str(PP)], ['', ''], ['NN: ' + str(NN), 'PN: ' + str(PN)]]))\n",
        "    accuracy = (PP + NN) / (PP + NN + NP + PN)\n",
        "    print('The total accuracy of this model on the data is %.2f%%' % (100*accuracy))        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ-drA595_S8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "7df1b871-2975-454c-d128-196c4afc4e9b"
      },
      "source": [
        "plot_confusion_matrix(y_true = labels[testData.index], y_pred = rf.predict(testData), title = 'RF')\n",
        "confusion_matrix_numbers(rf, testData)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------  ---------\n",
            "NP: 7266   PP: 14118\n",
            "\n",
            "NN: 37344  PN: 3772\n",
            "---------  ---------\n",
            "The total accuracy of this model on the data is 82.34%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEICAYAAADGG5iAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n94DoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbXjM8g-7oLD",
        "colab_type": "text"
      },
      "source": [
        "**Figure 1:** The confusion matrix for the RF model shows that the model was fairly accurate. In this matrix, *P* corresponds to an *s* label and *N* corresponds to a *b* label.\n",
        "\n",
        "The *N-N* block is very white, meaning there were many instances (37,344) that were truly *b* that were correctly predicted to be *b*.\n",
        "\n",
        "The hue of the *P-P* block falls around the middle range of the colorbar (14,118). This is darker than the *N-N* block, which means there were less instances that were truly *s* that were correctly predicted to be *s*. However, there were more *b* instances overall.\n",
        "\n",
        "The *N-P* and *P-N* blocks are very dark. This means that there were very few instances (7,266 and 3,772) that were incorrectly predicted.\n",
        "\n",
        "**Overall, 82.34% of the labels were correctly predicted.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIjFmF7D7nFN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "118cee30-4d6f-4908-c3c0-1d9c30412fdd"
      },
      "source": [
        "plot_confusion_matrix(y_true = labels[testData.index], y_pred = rf.predict(testData), title = 'GBT')\n",
        "confusion_matrix_numbers(gbt, testData)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------  ---------\n",
            "NP: 6227   PP: 15157\n",
            "\n",
            "NN: 36874  PN: 4242\n",
            "---------  ---------\n",
            "The total accuracy of this model on the data is 83.25%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEICAYAAADFrJaoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMwD+P+NnoUl5mL8JAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hy7FGU4BOkm",
        "colab_type": "text"
      },
      "source": [
        "**Figure 2:** The confusion matrix for the RF model shows that the model was fairly accurate. In this matrix, *P* corresponds to an *s* label and *N* corresponds to a *b* label.\n",
        "\n",
        "The *N-N* block is very white, meaning there were many instances (36,874) that were truly *b* that were correctly predicted to be *b*.\n",
        "\n",
        "The hue of the *P-P* block falls around the middle range of the colorbar (15,157\n",
        "). This is darker than the *N-N* block, which means there were less instances that were truly *s* that were correctly predicted to be *s*. However, there were more *b* instances overall.\n",
        "\n",
        "The *N-P* and *P-N* blocks are very dark. This means that there were very few instances (6,227 and 4,242) that were incorrectly predicted.\n",
        "\n",
        "**Overall, 83.25% of the labels were correctly predicted.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di6R9nJRBObB",
        "colab_type": "text"
      },
      "source": [
        "**Comparison**\n",
        "\n",
        "The random forest and gradient boosted models both had similar accuracy on the testing data. The random forest model had an accuracy of **82.34%** on the test data, while the gradient boosted model had a slightly higher accuracy of **83.25%**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_kdHBj6DktY",
        "colab_type": "text"
      },
      "source": [
        "## Predict the weights of the particles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbZQ3kMSQFK6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "- Use a Random Forest and a Gradiend Boosted Tree Regressor model to predict the weight of the particles. Compare the model performance on training and test setsm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5hyj7jdlKvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainWeights, testWeights = weights[trainData.index], weights[testData.index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_6uYj243Be_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traindata_weights, testdata_weights, train_weights, test_weights = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkanVFfO3HBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1cb527f1-b1e5-4f4a-d5c9-006029681eb0"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rfR = RandomForestRegressor(n_estimators=100, max_depth=3, random_state=0)\n",
        "rfR.fit(trainData, trainWeights)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                      warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYbj9dPbmISL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e4be4376-6cf4-40b9-d233-bf2ab7b3c3a5"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbtR = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=0)\n",
        "gbtR.fit(trainData, trainWeights)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
              "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                          n_iter_no_change=None, presort='auto', random_state=0,\n",
              "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
              "                          verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKvyqcFr3Z3d",
        "colab_type": "text"
      },
      "source": [
        "Calculate the L2 and L1 loss functions for the fitted regression models (see slides for the definition) and discuss the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "020fzW2OnsZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "dd1f0a3a-ff00-4157-e080-1869988e9c6a"
      },
      "source": [
        "L1 = sum(abs(testWeights - rfR.predict(testData)))\n",
        "L2 = sum((testWeights - rfR.predict(testData))**2)\n",
        "print('Random Forest Method: \\nL1: \\t%d \\nL2: \\t%d' % (L1, L2))\n",
        "\n",
        "L1 = sum(abs(testWeights - gbtR.predict(testData)))\n",
        "L2 = sum((testWeights - gbtR.predict(testData))**2)\n",
        "print('\\nGradient Boosting Method: \\nL1: \\t%d \\nL2: \\t%d' % (L1, L2))"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Method: \n",
            "L1: \t62814 \n",
            "L2: \t114399\n",
            "\n",
            "Gradient Boosting Method: \n",
            "L1: \t52788 \n",
            "L2: \t85175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggz2O7u12Kai",
        "colab_type": "text"
      },
      "source": [
        "The losses for the Gradient Boosting Method were smaller than the losses for the Random Forest Method. This implies that the GBT method is more accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G29xXSD2N1o",
        "colab_type": "text"
      },
      "source": [
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c38At7ayYd_5",
        "colab_type": "text"
      },
      "source": [
        "- For the Random Forest classifier, find the 4 most important features based on the simple unoptimized model you created earlier on. Use the documentation to find out what they are. We have not talked about the physics of this problem at all but the Kaggle challenge description should provide enogh information for you to comment on this result is somewhat superficially.\n",
        "\n",
        "You can use ```rf.feature_importance_``` on the trained model to extract the relative importance of each feature (a number from 0 to 1) and then choose the features that have the 4 highest numbers (the numpy function ```argsort()``` is helpful here!)\n",
        "\n",
        "Explore the parameter space with the sklearn module ```sklearn.model_selection.RandomizedSearchCV``` *fitting only those 4 features*\n",
        "\n",
        "Follow this example to set up the parameter search. Set the estimators to 10 and 100, (the number of trees) and the max depth to 3, and 10, and None (let it be unconstrained). Set bootstrap to both True and False. Set the number of features to consider at every split to both \"auto\" and \"sqrt\". Use ```pprint``` like I did earlier in this notebook to print the parameters set\n",
        "\n",
        "**this takes some computational time! so do not start this at the last minute!!**\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmTsSSEUqO2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "eb72249f-c218-4322-e34e-f0239f0c83fe"
      },
      "source": [
        "importances = [(i, j) for i, j in zip(trainData.columns, rf.feature_importances_)]\n",
        "importances.sort(key = lambda x: x[1], reverse = True)\n",
        "for i in range(4):\n",
        "  print(\"%30.30s:\\t %.2f\" % importances[i])\n",
        "bestFeatures = [importances[i][0] for i in range(4)]"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  DER_mass_MMC:\t 0.16\n",
            "   DER_mass_transverse_met_lep:\t 0.11\n",
            "                  DER_mass_vis:\t 0.07\n",
            "                    PRI_tau_pt:\t 0.06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-QQqGlp5ty3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_grid = {'max_depth': [3, 10, None], 'max_features': ['auto', 'sqrt'], 'n_estimators': [10, 100]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfdKk4Pk7tTz",
        "colab_type": "text"
      },
      "source": [
        " mine and your best features do not necessarily have to be the same because our models may be different (different parameters, different random seed etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmyw7x3EwTrz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "5feeb728-1f62-469d-d339-93ff060a059f"
      },
      "source": [
        "higgsData[bestFeatures]"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DER_mass_MMC</th>\n",
              "      <th>DER_mass_transverse_met_lep</th>\n",
              "      <th>DER_mass_vis</th>\n",
              "      <th>PRI_tau_pt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>138.470</td>\n",
              "      <td>51.655</td>\n",
              "      <td>97.827</td>\n",
              "      <td>32.638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>160.937</td>\n",
              "      <td>68.768</td>\n",
              "      <td>103.235</td>\n",
              "      <td>42.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-999.000</td>\n",
              "      <td>162.172</td>\n",
              "      <td>125.953</td>\n",
              "      <td>32.154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>143.905</td>\n",
              "      <td>81.417</td>\n",
              "      <td>80.943</td>\n",
              "      <td>22.647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>175.864</td>\n",
              "      <td>16.915</td>\n",
              "      <td>134.805</td>\n",
              "      <td>28.209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249995</th>\n",
              "      <td>-999.000</td>\n",
              "      <td>71.989</td>\n",
              "      <td>36.548</td>\n",
              "      <td>24.754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249996</th>\n",
              "      <td>-999.000</td>\n",
              "      <td>58.179</td>\n",
              "      <td>68.083</td>\n",
              "      <td>23.416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249997</th>\n",
              "      <td>105.457</td>\n",
              "      <td>60.526</td>\n",
              "      <td>75.839</td>\n",
              "      <td>35.636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249998</th>\n",
              "      <td>94.951</td>\n",
              "      <td>19.362</td>\n",
              "      <td>68.812</td>\n",
              "      <td>27.944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249999</th>\n",
              "      <td>-999.000</td>\n",
              "      <td>72.756</td>\n",
              "      <td>70.831</td>\n",
              "      <td>43.003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  PRI_tau_pt\n",
              "0            138.470                       51.655        97.827      32.638\n",
              "1            160.937                       68.768       103.235      42.014\n",
              "2           -999.000                      162.172       125.953      32.154\n",
              "3            143.905                       81.417        80.943      22.647\n",
              "4            175.864                       16.915       134.805      28.209\n",
              "...              ...                          ...           ...         ...\n",
              "249995      -999.000                       71.989        36.548      24.754\n",
              "249996      -999.000                       58.179        68.083      23.416\n",
              "249997       105.457                       60.526        75.839      35.636\n",
              "249998        94.951                       19.362        68.812      27.944\n",
              "249999      -999.000                       72.756        70.831      43.003\n",
              "\n",
              "[250000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3W60KM1Jb5r",
        "colab_type": "text"
      },
      "source": [
        "Note that this may take a long time! It took 1 hour for me to run this. Dont start at the last minute!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AJ70oqZPvL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f55c756b-bb44-4fac-e9eb-6308ac461751"
      },
      "source": [
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 18 different combinations\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator = rf, param_distributions=random_grid, n_iter=1, cv=3, iid=False)\n",
        "random_search.fit(higgsData[bestFeatures], labels);\n",
        "\n",
        "scores = random_search.cv_results_['split0_test_score'][0], random_search.cv_results_['split1_test_score'][0], random_search.cv_results_['split2_test_score'][0]\n",
        "print(\"Tuned RF  Parameters: %s, %s, %s, %s\" % (bestFeatures[0], bestFeatures[1], bestFeatures[2], bestFeatures[3]))\n",
        "print(\"Best score is %.4f\" % max(scores))"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tuned RF  Parameters: DER_mass_MMC, DER_mass_transverse_met_lep, DER_mass_vis, PRI_tau_pt\n",
            "Best score is 0.7968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaHvlFa27EV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "22d23f79-790c-42ae-d38b-b28b881b6148"
      },
      "source": [
        "df = pd.DataFrame(random_search.cv_results_)\n",
        "df"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.513457</td>\n",
              "      <td>0.313391</td>\n",
              "      <td>0.650082</td>\n",
              "      <td>0.018376</td>\n",
              "      <td>100</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>3</td>\n",
              "      <td>{'n_estimators': 100, 'max_features': 'sqrt', ...</td>\n",
              "      <td>0.795954</td>\n",
              "      <td>0.793734</td>\n",
              "      <td>0.796777</td>\n",
              "      <td>0.795488</td>\n",
              "      <td>0.001285</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0      12.513457      0.313391  ...        0.001285                1\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1r9zN9yI-at",
        "colab_type": "text"
      },
      "source": [
        "# Plot a simple 3-point ROC curve for the model with the best parameters found in the previous step. Describe it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl2NKYAy9LYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf.fit(trainData, labels[trainData.index].flatten()==\"s\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re9hOoJgC-L9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4b791d71-dd4e-418b-cb07-cc71d4b5b3c6"
      },
      "source": [
        "# The random forest model by itself\n",
        "from sklearn.metrics import roc_curve\n",
        "y_pred_grd_rfcat = rf.predict_proba(testData)[:, 1]\n",
        "\n",
        "fpr_rf, tpr_rf, _ = roc_curve(labels[testData.index].flatten()==\"s\", rf.predict(testData))\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5C2AhzMDXyd",
        "colab_type": "text"
      },
      "source": [
        "**Figure 3:** The ROC curve shows the trade-off between sensitivity (or TPR) and specificity (1 – FPR). In an ROC curve chart, a model is shown to be more accurate if it hugs the left axis moreso than it hugs the 45 degree line.\n",
        "\n",
        "This figure depicts the model having a steep increase at the beginning before flattening out."
      ]
    }
  ]
}